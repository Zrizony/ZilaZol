name: Daily Crawler

on:
  schedule:
    # Run daily at 07:00 AM UTC
    - cron: '0 7 * * *'
  workflow_dispatch: # Allow manual triggering

jobs:
  crawl_retailer:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false  # Continue other jobs even if one fails
      matrix:
        retailer:
          # Public retailers (no login required)
          - shufersal
          - carrefour
          - quik
          - victorymarket
          - superpharm
          - wolt
          - nativhachad
          - zolvebegadol
          - chokent
          - kingstore
          - maayan2000
          - goodpharm
          - machneshoshek
          - supersapir
          - superbareket
          - shukhayir
          - shefabirkathashem
          - citymarket
          - ktshivuk
          # Authenticated retailers (login required)
          - ramilevi
          - tivtaam
          - yohananof
          - doralon
          - osherad
          - salachd
          - stopmarket
          - politzer
          - yellow
          - superyuda
          - freshmarket
          - keshet
          - supercofix
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install Python dependencies
        working-directory: ZilaZol
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Install Playwright system dependencies
        working-directory: ZilaZol
        run: |
          npx playwright install-deps
      
      - name: Install Playwright browsers
        working-directory: ZilaZol
        run: |
          playwright install chromium
      
      - name: Run crawler for ${{ matrix.retailer }}
        working-directory: ZilaZol
        timeout-minutes: 330  # 5.5 hours per retailer (buffer before GitHub's 6h limit)
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          RETAILER_CREDS_JSON: ${{ secrets.RETAILER_CREDS_JSON }}
          LOG_LEVEL: INFO
          PYTHONPATH: ${{ github.workspace }}/ZilaZol
        run: |
          if [ -z "$DATABASE_URL" ]; then
            echo "Error: DATABASE_URL secret is not set"
            exit 1
          fi
          # Set timeout to 5 hours (300 minutes) to prevent hitting GitHub's 6h limit
          python run_crawler.py --retailer=${{ matrix.retailer }} --timeout=300
      
      - name: Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: crawler-logs-${{ matrix.retailer }}
          path: |
            ZilaZol/*.log
            ZilaZol/logs/
          if-no-files-found: ignore  # Don't fail if no logs found
